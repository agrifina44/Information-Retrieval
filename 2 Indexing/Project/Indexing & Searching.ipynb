{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.dom.minidom as minidom\n",
    "doc_xml = minidom.parse(\"trec.sample.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_doc_no = doc_xml.getElementsByTagName('DOCNO')\n",
    "all_profile = doc_xml.getElementsByTagName('PROFILE')\n",
    "all_date = doc_xml.getElementsByTagName('DATE')\n",
    "all_headline = doc_xml.getElementsByTagName('HEADLINE')\n",
    "all_text = doc_xml.getElementsByTagName('TEXT')\n",
    "all_pub = doc_xml.getElementsByTagName('PUB')\n",
    "all_page = doc_xml.getElementsByTagName('PAGE')\n",
    "\n",
    "N_DOC = len(all_doc_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sentence_doc = []\n",
    "for i in range(N_DOC):\n",
    "    sentence_doc = all_headline[i].firstChild.data +' '+ all_text[i].firstChild.data\n",
    "    all_sentence_doc.append(sentence_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"\\nFT  14 MAY 91 / (CORRECTED) Jubilee of a jet that did what it was designed\\nto do\\n \\nCorrection (published 16th May 1991) appended to this article.\\n'FRANK, it flies]' shouted someone at Sir Frank Whittle during the maiden\\nflight of a British jet. 'Of course it does,' replied Sir Frank, who\\npatented the first aircraft gas turbine. 'That's what it was bloody well\\ndesigned to do, wasn't it?'\\nExactly 50 years ago yesterday, the first British jet made a brief 17-minute\\nflight from RAF Cranwell in Lincolnshire. To celebrate the event, Mr Eric\\n'Winkle' Brown, a 72-year-old test pilot of the prototype Gloster Whittle\\njet, Mr Geoffrey Bone, a 73-year-old engineer, and Mr Charles McClure, a\\n75-year-old pilot, returned to RAF Cranwell. They are seen in front of a\\nrestored Meteor NF 11. Sir Frank was unable to attend because of ill-health.\\nThe Gloster Whittle was not the first jet to fly: a Heinkel 178 had its\\nmaiden flight in August 1939, 21 months before the British aircraft.\\nCorrection (published 16th May 1991).\\nTHE PICTURE of a Gloster Whittle jet on Page 7 of the issue of Tuesday May\\n14, was taken at Bournemouth Airport and not at RAF Cranwell as stated in\\nthe caption.\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentence_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens_doc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Punctuation, URL & Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_punc_tokenize(sentence):\n",
    "    tokens = []\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation,\" \")\n",
    "    \n",
    "    sentence = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', sentence, flags=re.MULTILINE)\n",
    "    for w in CountVectorizer().build_tokenizer()(sentence):\n",
    "        tokens.append(w)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(N_DOC):\n",
    "    tokens_doc.append(remove_punc_tokenize(all_sentence_doc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'FT',\n",
       " u'14',\n",
       " u'MAY',\n",
       " u'91',\n",
       " u'CORRECTED',\n",
       " u'Jubilee',\n",
       " u'of',\n",
       " u'jet',\n",
       " u'that',\n",
       " u'did',\n",
       " u'what',\n",
       " u'it',\n",
       " u'was',\n",
       " u'designed',\n",
       " u'to',\n",
       " u'do',\n",
       " u'Correction',\n",
       " u'published',\n",
       " u'16th',\n",
       " u'May',\n",
       " u'1991',\n",
       " u'appended',\n",
       " u'to',\n",
       " u'this',\n",
       " u'article',\n",
       " u'FRANK',\n",
       " u'it',\n",
       " u'flies',\n",
       " u'shouted',\n",
       " u'someone',\n",
       " u'at',\n",
       " u'Sir',\n",
       " u'Frank',\n",
       " u'Whittle',\n",
       " u'during',\n",
       " u'the',\n",
       " u'maiden',\n",
       " u'flight',\n",
       " u'of',\n",
       " u'British',\n",
       " u'jet',\n",
       " u'Of',\n",
       " u'course',\n",
       " u'it',\n",
       " u'does',\n",
       " u'replied',\n",
       " u'Sir',\n",
       " u'Frank',\n",
       " u'who',\n",
       " u'patented',\n",
       " u'the',\n",
       " u'first',\n",
       " u'aircraft',\n",
       " u'gas',\n",
       " u'turbine',\n",
       " u'That',\n",
       " u'what',\n",
       " u'it',\n",
       " u'was',\n",
       " u'bloody',\n",
       " u'well',\n",
       " u'designed',\n",
       " u'to',\n",
       " u'do',\n",
       " u'wasn',\n",
       " u'it',\n",
       " u'Exactly',\n",
       " u'50',\n",
       " u'years',\n",
       " u'ago',\n",
       " u'yesterday',\n",
       " u'the',\n",
       " u'first',\n",
       " u'British',\n",
       " u'jet',\n",
       " u'made',\n",
       " u'brief',\n",
       " u'17',\n",
       " u'minute',\n",
       " u'flight',\n",
       " u'from',\n",
       " u'RAF',\n",
       " u'Cranwell',\n",
       " u'in',\n",
       " u'Lincolnshire',\n",
       " u'To',\n",
       " u'celebrate',\n",
       " u'the',\n",
       " u'event',\n",
       " u'Mr',\n",
       " u'Eric',\n",
       " u'Winkle',\n",
       " u'Brown',\n",
       " u'72',\n",
       " u'year',\n",
       " u'old',\n",
       " u'test',\n",
       " u'pilot',\n",
       " u'of',\n",
       " u'the',\n",
       " u'prototype',\n",
       " u'Gloster',\n",
       " u'Whittle',\n",
       " u'jet',\n",
       " u'Mr',\n",
       " u'Geoffrey',\n",
       " u'Bone',\n",
       " u'73',\n",
       " u'year',\n",
       " u'old',\n",
       " u'engineer',\n",
       " u'and',\n",
       " u'Mr',\n",
       " u'Charles',\n",
       " u'McClure',\n",
       " u'75',\n",
       " u'year',\n",
       " u'old',\n",
       " u'pilot',\n",
       " u'returned',\n",
       " u'to',\n",
       " u'RAF',\n",
       " u'Cranwell',\n",
       " u'They',\n",
       " u'are',\n",
       " u'seen',\n",
       " u'in',\n",
       " u'front',\n",
       " u'of',\n",
       " u'restored',\n",
       " u'Meteor',\n",
       " u'NF',\n",
       " u'11',\n",
       " u'Sir',\n",
       " u'Frank',\n",
       " u'was',\n",
       " u'unable',\n",
       " u'to',\n",
       " u'attend',\n",
       " u'because',\n",
       " u'of',\n",
       " u'ill',\n",
       " u'health',\n",
       " u'The',\n",
       " u'Gloster',\n",
       " u'Whittle',\n",
       " u'was',\n",
       " u'not',\n",
       " u'the',\n",
       " u'first',\n",
       " u'jet',\n",
       " u'to',\n",
       " u'fly',\n",
       " u'Heinkel',\n",
       " u'178',\n",
       " u'had',\n",
       " u'its',\n",
       " u'maiden',\n",
       " u'flight',\n",
       " u'in',\n",
       " u'August',\n",
       " u'1939',\n",
       " u'21',\n",
       " u'months',\n",
       " u'before',\n",
       " u'the',\n",
       " u'British',\n",
       " u'aircraft',\n",
       " u'Correction',\n",
       " u'published',\n",
       " u'16th',\n",
       " u'May',\n",
       " u'1991',\n",
       " u'THE',\n",
       " u'PICTURE',\n",
       " u'of',\n",
       " u'Gloster',\n",
       " u'Whittle',\n",
       " u'jet',\n",
       " u'on',\n",
       " u'Page',\n",
       " u'of',\n",
       " u'the',\n",
       " u'issue',\n",
       " u'of',\n",
       " u'Tuesday',\n",
       " u'May',\n",
       " u'14',\n",
       " u'was',\n",
       " u'taken',\n",
       " u'at',\n",
       " u'Bournemouth',\n",
       " u'Airport',\n",
       " u'and',\n",
       " u'not',\n",
       " u'at',\n",
       " u'RAF',\n",
       " u'Cranwell',\n",
       " u'as',\n",
       " u'stated',\n",
       " u'in',\n",
       " u'the',\n",
       " u'caption']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_doc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Folding -> to lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_lower(tokens):\n",
    "    tokens = [x.lower() for x in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(N_DOC):\n",
    "    tokens_doc[i] = to_lower(tokens_doc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopping , remove number & Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def stop_word_token(tokens):\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    return tokens\n",
    "\n",
    "for i in range(N_DOC):\n",
    "    tokens_doc[i] = stop_word_token(tokens_doc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(N_DOC):\n",
    "    tokens_doc[i] = ([w for w in tokens_doc[i] if not any(j.isdigit() for j in w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "def stemming(tokens):\n",
    "    for i in range(0, len(tokens)):\n",
    "        if (tokens[i] != stemmer.stem(tokens[i])):\n",
    "            tokens[i] = stemmer.stem(tokens[i])\n",
    "    return tokens\n",
    "\n",
    "\n",
    "for i in range(N_DOC):\n",
    "    tokens_doc[i] = stemming(tokens_doc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ft',\n",
       " u'may',\n",
       " u'correct',\n",
       " u'jubile',\n",
       " u'jet',\n",
       " u'design',\n",
       " u'correct',\n",
       " u'publish',\n",
       " u'may',\n",
       " u'append',\n",
       " u'articl',\n",
       " u'frank',\n",
       " u'fli',\n",
       " u'shout',\n",
       " u'someon',\n",
       " u'sir',\n",
       " u'frank',\n",
       " u'whittl',\n",
       " u'maiden',\n",
       " u'flight',\n",
       " u'british',\n",
       " u'jet',\n",
       " u'cours',\n",
       " u'repli',\n",
       " u'sir',\n",
       " u'frank',\n",
       " u'patent',\n",
       " u'first',\n",
       " u'aircraft',\n",
       " u'ga',\n",
       " u'turbin',\n",
       " u'bloodi',\n",
       " u'well',\n",
       " u'design',\n",
       " u'exactli',\n",
       " u'year',\n",
       " u'ago',\n",
       " u'yesterday',\n",
       " u'first',\n",
       " u'british',\n",
       " u'jet',\n",
       " u'made',\n",
       " u'brief',\n",
       " u'minut',\n",
       " u'flight',\n",
       " u'raf',\n",
       " u'cranwel',\n",
       " u'lincolnshir',\n",
       " u'celebr',\n",
       " u'event',\n",
       " u'mr',\n",
       " u'eric',\n",
       " u'winkl',\n",
       " u'brown',\n",
       " u'year',\n",
       " u'old',\n",
       " u'test',\n",
       " u'pilot',\n",
       " u'prototyp',\n",
       " u'gloster',\n",
       " u'whittl',\n",
       " u'jet',\n",
       " u'mr',\n",
       " u'geoffrey',\n",
       " u'bone',\n",
       " u'year',\n",
       " u'old',\n",
       " u'engin',\n",
       " u'mr',\n",
       " u'charl',\n",
       " u'mcclure',\n",
       " u'year',\n",
       " u'old',\n",
       " u'pilot',\n",
       " u'return',\n",
       " u'raf',\n",
       " u'cranwel',\n",
       " u'seen',\n",
       " u'front',\n",
       " u'restor',\n",
       " u'meteor',\n",
       " u'nf',\n",
       " u'sir',\n",
       " u'frank',\n",
       " u'unabl',\n",
       " u'attend',\n",
       " u'ill',\n",
       " u'health',\n",
       " u'gloster',\n",
       " u'whittl',\n",
       " u'first',\n",
       " u'jet',\n",
       " u'fli',\n",
       " u'heinkel',\n",
       " u'maiden',\n",
       " u'flight',\n",
       " u'august',\n",
       " u'month',\n",
       " u'british',\n",
       " u'aircraft',\n",
       " u'correct',\n",
       " u'publish',\n",
       " u'may',\n",
       " u'pictur',\n",
       " u'gloster',\n",
       " u'whittl',\n",
       " u'jet',\n",
       " u'page',\n",
       " u'issu',\n",
       " u'tuesday',\n",
       " u'may',\n",
       " u'taken',\n",
       " u'bournemouth',\n",
       " u'airport',\n",
       " u'raf',\n",
       " u'cranwel',\n",
       " u'state',\n",
       " u'caption']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "for i in range(N_DOC):\n",
    "    for w in tokens_doc[i]:\n",
    "        all_tokens.append(w)\n",
    "\n",
    "new_sentence = ' '.join([w for w in all_tokens])\n",
    "\n",
    "for w in CountVectorizer().build_tokenizer()(new_sentence):\n",
    "    all_tokens.append(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove duplicate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tokens = set(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proximity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import izip as zip, count\n",
    "proximity_index = {}\n",
    "for token in all_tokens:\n",
    "    dict_doc_position = {}\n",
    "    for n in range(N_DOC):\n",
    "        if(token in tokens_doc[n]):\n",
    "            dict_doc_position[all_doc_no[n].firstChild.data] = [i for i, j in zip(count(), tokens_doc[n]) if j == token]\n",
    "    proximity_index[token] = dict_doc_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open('proximity index after remove number, stopping and stemming.txt','w')\n",
    "for key, value in proximity_index.iteritems():\n",
    "    file.write(key+'\\n')\n",
    "    for key, value in value.iteritems():\n",
    "        file.write('\\t'+str(key)+': ')\n",
    "        for i in range (len(value)):\n",
    "            file.write(str(value[i]))\n",
    "            if not(i == len(value)-1):\n",
    "                file.write(',')\n",
    "        file.write('\\n')\n",
    "    file.write('\\n')\n",
    "file.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3710\n",
      "3494\n",
      "3495\n",
      "3490\n",
      "3417\n",
      "3324\n",
      "3327\n",
      "24\n",
      "3795\n",
      "3790\n",
      "3816\n",
      "282\n",
      "287\n",
      "3760\n",
      "3835\n",
      "3830\n",
      "3937\n",
      "3932\n",
      "3405\n",
      "125\n",
      "3562\n",
      "3658\n",
      "375\n",
      "3822\n",
      "3820\n",
      "3829\n",
      "314\n",
      "112\n",
      "3673\n",
      "3387\n",
      "3470\n",
      "3472\n",
      "366\n",
      "361\n",
      "3580\n",
      "3582\n",
      "3666\n",
      "3661\n",
      "3817\n",
      "3586\n",
      "3589\n",
      "3818\n",
      "106\n",
      "248\n",
      "3390\n",
      "39\n",
      "3460\n",
      "3469\n",
      "3591\n",
      "3590\n",
      "3596\n",
      "3617\n",
      "3599\n",
      "65\n",
      "172\n",
      "171\n",
      "3699\n",
      "3519\n",
      "3694\n",
      "3602\n",
      "3606\n",
      "3608\n",
      "92\n",
      "161\n",
      "163\n",
      "3449\n",
      "16\n",
      "3444\n",
      "3396\n",
      "3441\n",
      "3834\n",
      "3636\n",
      "3865\n",
      "3533\n",
      "3535\n",
      "3537\n",
      "3939\n",
      "3734\n",
      "3439\n",
      "3343\n",
      "42\n",
      "3345\n",
      "326\n",
      "141\n",
      "3708\n",
      "3709\n",
      "3700\n",
      "3706\n",
      "3707\n",
      "3705\n",
      "3542\n",
      "3788\n",
      "351\n",
      "3404\n"
     ]
    }
   ],
   "source": [
    "for key,value in proximity_index['incom'].iteritems():\n",
    "    print key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collection_matrix = {}\n",
    "for token in all_tokens:\n",
    "    matrix = []\n",
    "    for i in range(N_DOC):\n",
    "        if(token in tokens_doc[i]):\n",
    "            matrix.append('1')\n",
    "        else:\n",
    "            matrix.append('0')\n",
    "    collection_matrix[token] = matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " income OR taxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income OR taxes\n",
      "0000000000000001000000010000000000000010010000000000000000000000100000000000000000000000000100000000000001000001000000000000100000000000000010000000000000000000101000000011000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000010000100000000000000000000000000100000000000100000000000000000000000010000000001000010000000010100100000000000000010100000000000000000000000000000000000000000100100000100000001100000000000100000000000000000000010100100001000000000010000000011010000000000000000010001100000000000000000000000100000000000001010100001000000000000000000010000000000000000010100010011100001001001000101000000001000000000000000000100000000000000000000010010000100000010000000000000000000010000110000111111000000000000000000000001000000000000000000000000010000000000000000000000000001010000100000000000000000000111010100000011000110000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000001000010100000000\n",
      "OR\n",
      "0010000000000101000000110000000111000010101001000000000000000000100000000000000000000000000100000000000000000000100000000000000000000000000010010100000000000000001000010101101011000001110001000000000000000000000000010000000001010000000000001000000000000000100001000001010000000000010000000000000000000001000000001111101001001101100000000000000000000000000010011000000001000000000101011100110001110001000000000000000000000000001000000000000110000000010001010101010010010000100000000000000001000101000001000000000000000000000001110000111000000010000100100001100000010000000100000101111111010000000100001000000000000111000101000000000000100000011011011101000010111011110001100010010011100000000000000000000001100000000000000100100000001000000000001100000101001111101000110000000000100000001000000000000000000000000000000000000100010000010000000000110000000000010000001000111001001011110100110010011000101100000000000000000001000000100000000000001000000000010000000000010000000000000011000000010000000000\n",
      "=\n",
      "0010000000000101000000110000000111000010111001000000000000000000100000000000000000000000000100000000000001000001100000000000100000000000000010010100000000000000101000010111101011000001110001000000000000000000000000010000000001010000000000001000000100000000100001000001010000000000010000100000000000000001000000001111101001001101100000000000000000000010000010011000010001000010100101011100110001110101000000000000000000000000001000000000000110100000110001011101010010010100100000000000000001010101100001000000000010000000011011110000111000000010001100100001100000010000000100000101111111010100001100001000000000000111000101000000000010100010011111011101001010111011110001100010010011100000100000000000000001100010010000100100110000001000000000001110000111001111111000110000000000100000001000000000000000000000000010000000000100010000010000001010110100000000010000001000111011101011111100110010011000101100000000000000010001000000100000000000001000000000010000000000010000000000000011001000010100000000\n",
      "Maka Hasil Query income OR taxes Terdapat Pada Nomor Dokumen : \n",
      "3, 14, 16, 23, 24, 32, 33, 34, 39, 41, 42, 43, 46, 65, 92, 106, 112, 113, 125, 141, 144, 146, 161, 163, 168, 170, 171, 172, 173, 175, 177, 178, 184, 185, 186, 190, 216, 226, 228, 241, 248, 257, 262, 268, 270, 282, 287, 304, 313, 314, 315, 316, 317, 319, 322, 325, 326, 328, 329, 351, 357, 360, 361, 366, 370, 375, 3324, 3327, 3329, 3331, 3332, 3333, 3336, 3337, 3341, 3342, 3343, 3345, 3347, 3374, 3387, 3388, 3390, 3396, 3397, 3401, 3403, 3404, 3405, 3407, 3409, 3412, 3415, 3417, 3420, 3437, 3439, 3441, 3443, 3444, 3449, 3460, 3469, 3470, 3472, 3473, 3474, 3475, 3480, 3481, 3482, 3490, 3494, 3495, 3498, 3503, 3504, 3511, 3519, 3525, 3527, 3528, 3529, 3530, 3531, 3532, 3533, 3535, 3537, 3542, 3543, 3548, 3561, 3562, 3563, 3567, 3569, 3580, 3582, 3586, 3589, 3590, 3591, 3592, 3593, 3595, 3596, 3597, 3599, 3602, 3604, 3606, 3607, 3608, 3610, 3611, 3612, 3613, 3617, 3618, 3622, 3625, 3628, 3629, 3630, 3636, 3653, 3654, 3658, 3661, 3666, 3669, 3672, 3673, 3680, 3692, 3693, 3694, 3699, 3700, 3701, 3704, 3705, 3706, 3707, 3708, 3709, 3710, 3714, 3715, 3726, 3734, 3760, 3771, 3775, 3781, 3788, 3790, 3792, 3793, 3795, 3805, 3812, 3816, 3817, 3818, 3820, 3821, 3822, 3824, 3826, 3827, 3828, 3829, 3830, 3831, 3834, 3835, 3838, 3841, 3842, 3846, 3848, 3849, 3865, 3869, 3876, 3890, 3901, 3913, 3928, 3929, 3932, 3937, 3939\n"
     ]
    }
   ],
   "source": [
    "income_biner = ''.join(collection_matrix['incom'])\n",
    "taxes_biner = ''.join(collection_matrix['tax'])\n",
    "print 'income OR taxes'\n",
    "print income_biner+'\\nOR\\n'+taxes_biner\n",
    "str_result = format(int(income_biner, 2) | int(taxes_biner, 2), '01000b')\n",
    "print '=\\n'+str_result+'\\nMaka Hasil Query income OR taxes Terdapat Pada Nomor Dokumen : '\n",
    "str_result_list = [i for i in str_result]\n",
    "str_result_doc_no = []\n",
    "for n in [i for i, j in zip(count(), str_result_list) if j == '1']:\n",
    "    str_result_doc_no.append(all_doc_no[n].firstChild.data)\n",
    "print u', '.join(str_result_doc_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " income AND taxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income AND taxes\n",
      "0000000000000001000000010000000000000010010000000000000000000000100000000000000000000000000100000000000001000001000000000000100000000000000010000000000000000000101000000011000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000010000100000000000000000000000000100000000000100000000000000000000000010000000001000010000000010100100000000000000010100000000000000000000000000000000000000000100100000100000001100000000000100000000000000000000010100100001000000000010000000011010000000000000000010001100000000000000000000000100000000000001010100001000000000000000000010000000000000000010100010011100001001001000101000000001000000000000000000100000000000000000000010010000100000010000000000000000000010000110000111111000000000000000000000001000000000000000000000000010000000000000000000000000001010000100000000000000000000111010100000011000110000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000001000010100000000\n",
      "AND\n",
      "0010000000000101000000110000000111000010101001000000000000000000100000000000000000000000000100000000000000000000100000000000000000000000000010010100000000000000001000010101101011000001110001000000000000000000000000010000000001010000000000001000000000000000100001000001010000000000010000000000000000000001000000001111101001001101100000000000000000000000000010011000000001000000000101011100110001110001000000000000000000000000001000000000000110000000010001010101010010010000100000000000000001000101000001000000000000000000000001110000111000000010000100100001100000010000000100000101111111010000000100001000000000000111000101000000000000100000011011011101000010111011110001100010010011100000000000000000000001100000000000000100100000001000000000001100000101001111101000110000000000100000001000000000000000000000000000000000000100010000010000000000110000000000010000001000111001001011110100110010011000101100000000000000000001000000100000000000001000000000010000000000010000000000000011000000010000000000\n",
      "=\n",
      "0000000000000001000000010000000000000010000000000000000000000000100000000000000000000000000100000000000000000000000000000000000000000000000010000000000000000000001000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000100000000000100000000000000000000000000000000001000000000000000000100000000000000010000000000000000000000000000000000000000000100000000000000000100000000000000000000000000000000000100000001000000000000000000000000000000000000000010000100000000000000000000000100000000000001010000000000000000000000000010000000000000000000100000011000001001000000101000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000100000111101000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000111000000000010000110000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000\n",
      "Maka Hasil Query income AND taxes Terdapat Pada Nomor Dokumen : \n",
      "16, 24, 39, 65, 92, 141, 163, 172, 282, 314, 326, 361, 3327, 3343, 3387, 3405, 3441, 3449, 3490, 3495, 3519, 3533, 3535, 3562, 3582, 3589, 3590, 3596, 3599, 3606, 3608, 3617, 3699, 3705, 3706, 3707, 3708, 3710, 3734, 3816, 3817, 3818, 3829, 3834, 3835, 3937\n"
     ]
    }
   ],
   "source": [
    "income_biner = ''.join(collection_matrix['incom'])\n",
    "taxes_biner = ''.join(collection_matrix['tax'])\n",
    "print 'income AND taxes'\n",
    "print income_biner+'\\nAND\\n'+taxes_biner\n",
    "str_result = format(int(income_biner, 2) & int(taxes_biner, 2), '01000b')\n",
    "print '=\\n'+str_result+'\\nMaka Hasil Query income AND taxes Terdapat Pada Nomor Dokumen : '\n",
    "str_result_list = [i for i in str_result]\n",
    "str_result_doc_no = []\n",
    "for n in [i for i, j in zip(count(), str_result_list) if j == '1']:\n",
    "    str_result_doc_no.append(all_doc_no[n].firstChild.data)\n",
    "print u', '.join(str_result_doc_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scotland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Query Scotland Terdapat Pada Nomor Dokumen :\n",
      "16, 94, 96, 143, 272, 351, 370, 3330, 3334, 3336, 3338, 3376, 3485, 3504, 3505, 3532, 3533, 3561, 3565, 3629, 3654, 3820, 3826, 3932, 3938\n"
     ]
    }
   ],
   "source": [
    "print('Hasil Query Scotland Terdapat Pada Nomor Dokumen :')\n",
    "str_result_doc_no = []\n",
    "for n in [i for i, j in zip(count(), collection_matrix['scotland']) if j == '1']:\n",
    "    str_result_doc_no.append(all_doc_no[n].firstChild.data)\n",
    "print u', '.join(str_result_doc_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Query Window Terdapat Pada Nomor Dokumen :\n",
      "30, 55, 59, 145, 160, 272, 374, 3463, 3639, 3782, 3788, 3906, 3909, 3910, 3917, 3930\n"
     ]
    }
   ],
   "source": [
    "print('Hasil Query Window Terdapat Pada Nomor Dokumen :')\n",
    "str_result_doc_no = []\n",
    "for n in [i for i, j in zip(count(), collection_matrix['window']) if j == '1']:\n",
    "    str_result_doc_no.append(all_doc_no[n].firstChild.data)\n",
    "print u', '.join(str_result_doc_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Query replacing Terdapat Pada Nomor Dokumen :\n",
      "16, 28, 31, 51, 92, 97, 131, 135, 136, 138, 140, 169, 195, 197, 218, 242, 256, 274, 276, 325, 3325, 3342, 3361, 3370, 3387, 3397, 3403, 3410, 3411, 3413, 3418, 3437, 3438, 3461, 3494, 3504, 3521, 3531, 3532, 3533, 3561, 3598, 3623, 3654, 3660, 3662, 3668, 3693, 3700, 3716, 3720, 3724, 3734, 3745, 3788, 3805, 3828, 3867, 3869, 3876, 3886, 3895, 3896, 3907, 3918, 3921, 3930, 3935\n"
     ]
    }
   ],
   "source": [
    "print('Hasil Query replacing Terdapat Pada Nomor Dokumen :')\n",
    "str_result_doc_no = []\n",
    "for n in [i for i, j in zip(count(), collection_matrix['replac']) if j == '1']:\n",
    "    str_result_doc_no.append(all_doc_no[n].firstChild.data)\n",
    "print u', '.join(str_result_doc_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "condemning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Query condemning Terdapat Pada Nomor Dokumen :\n",
      "113, 309, 354, 3374, 3674, 3678\n"
     ]
    }
   ],
   "source": [
    "print('Hasil Query condemning Terdapat Pada Nomor Dokumen :')\n",
    "str_result_doc_no = []\n",
    "for n in [i for i, j in zip(count(), collection_matrix['condemn']) if j == '1']:\n",
    "    str_result_doc_no.append(all_doc_no[n].firstChild.data)\n",
    "print u', '.join(str_result_doc_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bi-gram Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bi_gram_tokens = []\n",
    "bi_gram_sentence_doc = []\n",
    "\n",
    "for n in range(N_DOC):\n",
    "    token = []\n",
    "    for i in range(len(tokens_doc[n])):\n",
    "        if not(i == len(tokens_doc[n])-1):            \n",
    "            token.append(tokens_doc[n][i]+'_'+tokens_doc[n][i+1])\n",
    "            bi_gram_tokens.append(tokens_doc[n][i]+'_'+tokens_doc[n][i+1])\n",
    "    bi_gram_sentence_doc.append(' '.join(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bi_gram_index = {}\n",
    "for bigram_token in bigram_tokens:\n",
    "    doc_no = []\n",
    "    for i in range(N_DOC):\n",
    "        if(bigram_token in bi_gram_sentence_doc[i]):\n",
    "            doc_no.append(all_doc_no[i].firstChild.data)\n",
    "    bi_gram_index[bigram_token] = doc_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Query income_taxes Terdapat Pada Nomor Dokumen :\n",
      "65, 92, 282, 361, 3405, 3441, 3449, 3562, 3706, 3708, 3734, 3818\n"
     ]
    }
   ],
   "source": [
    "print('Hasil Query income_taxes Terdapat Pada Nomor Dokumen :')\n",
    "print u', '.join(bi_gram_index['incom_tax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proximity_search(a,b,w):\n",
    "    prox_doc = []\n",
    "    for i in range(N_DOC):\n",
    "        if(a in tokens_doc[i] and b in tokens_doc[i]):\n",
    "            for key1,value1 in proximity_index[a].iteritems():\n",
    "                if(key1 == all_doc_no[i].firstChild.data):\n",
    "                    for v1 in value1:\n",
    "                        for key2,value2 in proximity_index[b].iteritems():\n",
    "                            if(key2 == all_doc_no[i].firstChild.data):\n",
    "                                for v2 in value2:\n",
    "                                    if(abs(v1-v2) < w):\n",
    "                                        prox_doc.append(all_doc_no[i].firstChild.data)\n",
    "                                        break\n",
    "    return prox_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#10(income, taxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Query #10(income, taxes) Terdapat Pada Nomor Dokumen :\n",
      "3562, 3387, 92, 3449, 3817, 3734, 3699, 3599, 3441, 3533, 3708, 163, 3405, 65, 282, 3706, 3818, 361\n"
     ]
    }
   ],
   "source": [
    "result = set(proximity_search('incom','tax',10))\n",
    "print('Hasil Query #10(income, taxes) Terdapat Pada Nomor Dokumen :')\n",
    "print u', '.join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"middle east\" AND peace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle east\n",
      "0000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000010000000000000000000000010001000000000000000000000000000000000000000000000000000000000000000010000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000010000000000000000000000000011000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001010100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000100010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000\n",
      "AND\n",
      "peace\n",
      "0000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010001000000000000000000000000000000000000000000000000000000000000001010000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000100010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "=\n",
      "0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010001000000000000000000000000000000000000000000000000000000000000000010000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "Maka Hasil Query \"middle east\" AND peace Terdapat Pada Nomor Dokumen : \n",
      "219, 223, 288, 305, 3549, 3663, 3762, 3766\n"
     ]
    }
   ],
   "source": [
    "result_middle_east = bi_gram_index['middl_east']\n",
    "biner_middle_east = ''\n",
    "for i in range(N_DOC):\n",
    "    if(all_doc_no[i].firstChild.data in result_middle_east):\n",
    "        biner_middle_east+='1'\n",
    "    else:\n",
    "        biner_middle_east+='0'\n",
    "biner_peace = ''.join(collection_matrix['peac'])\n",
    "print 'middle east'\n",
    "print biner_middle_east\n",
    "print 'AND'\n",
    "print 'peace'\n",
    "print biner_peace\n",
    "str_result = format(int(biner_middle_east, 2) & int(biner_peace, 2), '01000b')\n",
    "print '=\\n'+str_result+'\\nMaka Hasil Query \"middle east\" AND peace Terdapat Pada Nomor Dokumen : '\n",
    "str_result_list = [i for i in str_result]\n",
    "str_result_doc_no = []\n",
    "for n in [i for i, j in zip(count(), str_result_list) if j == '1']:\n",
    "    str_result_doc_no.append(all_doc_no[n].firstChild.data)\n",
    "print u', '.join(str_result_doc_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\nFT  14 MAY 91 / Israel to seek EC law on Arab boycott of companies\\n \\nISRAEL is expected today to ask Brussels to extend the anti-Arab-boycott\\nlegislation that already exists in two EC states to Community level.\\nThe expected request by Mr David Levy, the Israeli foreign minister, to a\\nformal EC-Israel meeting here coincides with growing interest in the\\nCommunity, as well as the US, in at least an easing of the Arab boycott of\\ncompanies trading with Israel as a confidence-building measure to boost\\nMiddle East peace efforts.\\nOn Saturday, several EC foreign ministers urged the six Gulf Co-operation\\nCouncil members to use their influence within the Arab League for an easing\\nof the boycott. The latter said this was only conceivable in the context of\\nan Arab-Israeli peace deal.\\nFrance and the Netherlands have national laws forbidding their companies to\\ngive the Arab Boycott Office formal undertakings they will not trade with\\nIsrael.\\nThe Israeli government wants such legislation adopted by the EC as a whole,\\narguing, among other points, that general Arab incitement creates commercial\\ndistortion.\\nGermany and Denmark now sympathise with the Israeli view, but most other EC\\nstates want to wait and see how Israel responds to peace overtures and\\nprefer to exert quiet political pressure on the Arabs.\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentence_doc[218]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
